{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.0, 66.0, 2.0, 1.0, 89.0]\n",
      "102893\n",
      "1273\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Pre-process the data\n",
    "training_data = []\n",
    "\n",
    "# Set up tokenizer, bag of words, and make a defaultdict to hold a tuple of (tweets_text, [scores]) for each\n",
    "# Loop through the files\n",
    "tokenizer = TweetTokenizer(strip_handles=True)\n",
    "tweets_and_scores = defaultdict(tuple)\n",
    "#bag_of_words = []\n",
    "word_dict = defaultdict(int)\n",
    "\n",
    "# Grab the scores\n",
    "scores = pd.DataFrame.from_csv('scraped_twitter_score.csv')\n",
    "print(list(scores.ix[\"lordhamstr\"]))\n",
    "\n",
    "# Grab the tweets and scores\n",
    "for tweet_file in os.listdir('statuses'):\n",
    "    if tweet_file.endswith('_output.txt'):\n",
    "        # Get the handle\n",
    "        beginning = 9\n",
    "        ending = tweet_file.index('_output.txt')\n",
    "        handle = tweet_file[beginning:ending]\n",
    "        \n",
    "        # Put the text and scores in a dictionary\n",
    "        with open('statuses/' + tweet_file, 'r', encoding='utf8') as tweet_text:\n",
    "            score = list(scores.ix[handle])\n",
    "            text = tokenizer.tokenize(tweet_text.read().replace('\\nTWEETLINEBREAK\\n', ' '))\n",
    "            #bag_of_words += text\n",
    "            for word in text:\n",
    "                word_dict[word] += 1\n",
    "            tweets_and_scores[handle] = (text, score)\n",
    "            \n",
    "#bag_of_words = set(bag_of_words)\n",
    "print(len(word_dict))\n",
    "bag_of_words = {word:n for word,n in word_dict.items() if n in range(40,100)}.keys()\n",
    "num_words = len(bag_of_words)\n",
    "print(num_words)\n",
    "num_observations = len(tweets_and_scores)\n",
    "\n",
    "# From this, you have a dictionary called tweets_and_scores and a list called bag_of_words\n",
    "\n",
    "# Convert tweets_texts into vector of words\n",
    "\n",
    "# Make X matrix of size [len(trainingdata), bag_of_words_length]\n",
    "X = np.zeros([num_observations, num_words])\n",
    "\n",
    "# Make Y matrix of size [len(trainingdata), 5] to hold personality scores\n",
    "Y_array = [np.zeros([num_observations, 1]) for x in range(0,5)]\n",
    "\n",
    "# Fill them\n",
    "index = 0\n",
    "for (key, (words, scores)) in tweets_and_scores.items():\n",
    "    word_index = 0\n",
    "    for word in bag_of_words:\n",
    "        if word in words:\n",
    "            X[index][word_index] = words.count(word)\n",
    "        word_index += 1\n",
    "    \n",
    "    score_index = 0\n",
    "    for score in scores:\n",
    "        if score > 50:\n",
    "            Y_array[score_index][index] = 1\n",
    "        else:\n",
    "            Y_array[score_index][index] = 0\n",
    "        score_index += 1\n",
    "    \n",
    "    print(index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the model\n",
    "### This is for quickly testing different score thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for (key, (words, scores)) in tweets_and_scores.items():\n",
    "    score_index = 0\n",
    "    for score in scores:\n",
    "        if score > 50:\n",
    "            Y_array[score_index][index] = 1\n",
    "        else:\n",
    "            Y_array[score_index][index] = 0\n",
    "        score_index += 1\n",
    "    \n",
    "    print(index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds: 4\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.736842  0.815789  0.710526\n",
      "Precision  0.756757  0.823529       0.8\n",
      "Recall     0.965517  0.965517  0.827586\n",
      "F1         0.848485  0.888889  0.813559\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.421053  0.605263  0.526316\n",
      "Precision       0.5      0.64  0.576923\n",
      "Recall     0.545455  0.727273  0.681818\n",
      "F1         0.521739  0.680851     0.625\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy        0.5  0.631579  0.657895\n",
      "Precision       0.5  0.580645     0.625\n",
      "Recall     0.526316  0.947368  0.789474\n",
      "F1         0.512821      0.72  0.697674\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.789474  0.789474  0.710526\n",
      "Precision       0.8  0.818182  0.821429\n",
      "Recall     0.965517  0.931034  0.793103\n",
      "F1            0.875  0.870968  0.807018\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy        0.5  0.605263  0.421053\n",
      "Precision       0.5  0.642857       0.4\n",
      "Recall     0.473684  0.473684  0.315789\n",
      "F1         0.486486  0.545455  0.352941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "\n",
    "df_o = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_c = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_e = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_a = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_n = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "dfs = [df_o, df_c, df_e, df_a, df_n]\n",
    "\n",
    "n_folds = 4\n",
    "k_fold = KFold(num_observations, n_folds=n_folds, shuffle=True, random_state=0)\n",
    "\n",
    "index = 0\n",
    "for Y in Y_array:\n",
    "    mnb = GaussianNB()\n",
    "    predictions = cross_val_predict(mnb, X, Y.ravel(), cv=k_fold, n_jobs=1)\n",
    "    dfs[index][\"Gaussian\"][0] = metrics.accuracy_score(Y, predictions)\n",
    "    dfs[index][\"Gaussian\"][1] = metrics.precision_score(Y, predictions)\n",
    "    dfs[index][\"Gaussian\"][2] = metrics.recall_score(Y, predictions)\n",
    "    dfs[index][\"Gaussian\"][3] = metrics.f1_score(Y, predictions)\n",
    "    \n",
    "    mnb = MultinomialNB()\n",
    "    predictions = cross_val_predict(mnb, X, Y.ravel(), cv=k_fold, n_jobs=1)\n",
    "    dfs[index][\"MNB\"][0] = metrics.accuracy_score(Y, predictions)\n",
    "    dfs[index][\"MNB\"][1] = metrics.precision_score(Y, predictions)\n",
    "    dfs[index][\"MNB\"][2] = metrics.recall_score(Y, predictions)\n",
    "    dfs[index][\"MNB\"][3] = metrics.f1_score(Y, predictions)\n",
    "    \n",
    "    mnb = BernoulliNB()\n",
    "    predictions = cross_val_predict(mnb, X, Y.ravel(), cv=k_fold, n_jobs=1)\n",
    "    dfs[index][\"Bernoulli\"][0] = metrics.accuracy_score(Y, predictions)\n",
    "    dfs[index][\"Bernoulli\"][1] = metrics.precision_score(Y, predictions)\n",
    "    dfs[index][\"Bernoulli\"][2] = metrics.recall_score(Y, predictions)\n",
    "    dfs[index][\"Bernoulli\"][3] = metrics.f1_score(Y, predictions)\n",
    "    index += 1\n",
    "    \n",
    "print(\"Folds: \" + str(n_folds))\n",
    "print()\n",
    "for df in dfs:\n",
    "    print(df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['initial_model_counts.pkl',\n",
       " 'initial_model_counts.pkl_01.npy',\n",
       " 'initial_model_counts.pkl_02.npy',\n",
       " 'initial_model_counts.pkl_03.npy',\n",
       " 'initial_model_counts.pkl_04.npy',\n",
       " 'initial_model_counts.pkl_05.npy']"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X, Y.ravel())\n",
    "coefs = mnb.coef_[0]\n",
    "\n",
    "bag = list(bag_of_words)\n",
    "\n",
    "word_coefs = []\n",
    "for i in range(len(bag)):\n",
    "    word_coefs.append((bag[i], coefs[i]))\n",
    "    \n",
    "word_coefs.sort(key=lambda tup: tup[1])\n",
    "\n",
    "predictions = mnb.predict(X)\n",
    "print(metrics.accuracy_score(Y, predictions))\n",
    "print(metrics.precision_score(Y, predictions))\n",
    "print(metrics.recall_score(Y, predictions))\n",
    "print(metrics.f1_score(Y, predictions))\n",
    "\n",
    "# Use initial model counts for all but extroversion\n",
    "joblib.dump(mnb, 'initial_model_counts.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
