{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.0, 66.0, 2.0, 1.0, 89.0]\n",
      "102893\n",
      "1273\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Pre-process the data\n",
    "training_data = []\n",
    "\n",
    "# Set up tokenizer, bag of words, and make a defaultdict to hold a tuple of (tweets_text, [scores]) for each\n",
    "# Loop through the files\n",
    "tokenizer = TweetTokenizer(strip_handles=True)\n",
    "tweets_and_scores = defaultdict(tuple)\n",
    "#bag_of_words = []\n",
    "word_dict = defaultdict(int)\n",
    "\n",
    "# Grab the scores\n",
    "scores = pd.DataFrame.from_csv('scraped_twitter_score.csv')\n",
    "print(list(scores.ix[\"lordhamstr\"]))\n",
    "\n",
    "# Grab the tweets and scores\n",
    "handles = list(scores.index)\n",
    "for tweet_file in os.listdir('statuses'):\n",
    "    if tweet_file.endswith('_output.txt'):\n",
    "        # Get the handle\n",
    "        beginning = 9\n",
    "        ending = tweet_file.index('_output.txt')\n",
    "        handle = tweet_file[beginning:ending]\n",
    "        \n",
    "        if handle in handles:\n",
    "            # Put the text and scores in a dictionary\n",
    "            with open('statuses/' + tweet_file, 'r', encoding='utf8') as tweet_text:\n",
    "                score = list(scores.ix[handle])\n",
    "                text = tokenizer.tokenize(tweet_text.read().replace('\\nTWEETLINEBREAK\\n', ' '))\n",
    "                #bag_of_words += text\n",
    "                for word in text:\n",
    "                    word_dict[word] += 1\n",
    "                tweets_and_scores[handle] = (text, score)\n",
    "            \n",
    "#bag_of_words = set(bag_of_words)\n",
    "print(len(word_dict))\n",
    "bag_of_words = {word:n for word,n in word_dict.items() if n in range(40,100)}.keys()\n",
    "num_words = len(bag_of_words)\n",
    "print(num_words)\n",
    "num_observations = len(tweets_and_scores)\n",
    "\n",
    "# From this, you have a dictionary called tweets_and_scores and a list called bag_of_words\n",
    "\n",
    "# Convert tweets_texts into vector of words\n",
    "\n",
    "# Make X matrix of size [len(trainingdata), bag_of_words_length]\n",
    "X = np.zeros([num_observations, num_words + 1])\n",
    "\n",
    "# Make Y matrix of size [len(trainingdata), 5] to hold personality scores\n",
    "Y_array = [np.zeros([num_observations, 1]) for x in range(0,5)]\n",
    "\n",
    "# Fill them\n",
    "index = 0\n",
    "for (key, (words, scores)) in tweets_and_scores.items():\n",
    "    word_index = 0\n",
    "    wordcount = 0\n",
    "    wordlen = 0\n",
    "    for word in bag_of_words:\n",
    "        if word in words:\n",
    "            X[index][word_index] = words.count(word)\n",
    "            wordcount += 1\n",
    "            wordlen += len(word)\n",
    "        word_index += 1\n",
    "    X[index][-1] = wordlen / wordcount\n",
    "    \n",
    "    \n",
    "    score_index = 0\n",
    "    for score in scores:\n",
    "        if score > 50:\n",
    "            Y_array[score_index][index] = 1\n",
    "        else:\n",
    "            Y_array[score_index][index] = 0\n",
    "        score_index += 1\n",
    "    \n",
    "    print(index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the model\n",
    "### This is for quickly testing different score thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for (key, (words, scores)) in tweets_and_scores.items():\n",
    "    score_index = 0\n",
    "    for score in scores:\n",
    "        if score > 50:\n",
    "            Y_array[score_index][index] = 1\n",
    "        else:\n",
    "            Y_array[score_index][index] = 0\n",
    "        score_index += 1\n",
    "    \n",
    "    print(index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds: 4\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.736842  0.842105  0.763158\n",
      "Precision  0.771429  0.848485  0.763158\n",
      "Recall     0.931034  0.965517         1\n",
      "F1          0.84375  0.903226  0.865672\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.447368  0.605263  0.526316\n",
      "Precision  0.521739   0.62963  0.558824\n",
      "Recall     0.545455  0.772727  0.863636\n",
      "F1         0.533333  0.693878  0.678571\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy        0.5  0.578947  0.368421\n",
      "Precision       0.5  0.548387  0.407407\n",
      "Recall     0.631579  0.894737  0.578947\n",
      "F1          0.55814      0.68  0.478261\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.789474  0.815789  0.763158\n",
      "Precision  0.783784  0.823529  0.763158\n",
      "Recall            1  0.965517         1\n",
      "F1         0.878788  0.888889  0.865672\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.657895  0.657895  0.631579\n",
      "Precision  0.666667  0.666667  0.647059\n",
      "Recall     0.631579  0.631579  0.578947\n",
      "F1         0.648649  0.648649  0.611111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "\n",
    "df_o = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_c = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_e = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_a = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_n = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "dfs = [df_o, df_c, df_e, df_a, df_n]\n",
    "\n",
    "n_folds = 4\n",
    "k_fold = KFold(num_observations, n_folds=n_folds, shuffle=True, random_state=0)\n",
    "\n",
    "index = 0\n",
    "for Y in Y_array:\n",
    "    mnb = GaussianNB()\n",
    "    predictions = cross_val_predict(mnb, X, Y.ravel(), cv=4, n_jobs=1)\n",
    "    dfs[index][\"Gaussian\"][0] = metrics.accuracy_score(Y, predictions)\n",
    "    dfs[index][\"Gaussian\"][1] = metrics.precision_score(Y, predictions)\n",
    "    dfs[index][\"Gaussian\"][2] = metrics.recall_score(Y, predictions)\n",
    "    dfs[index][\"Gaussian\"][3] = metrics.f1_score(Y, predictions)\n",
    "    \n",
    "    mnb = MultinomialNB()\n",
    "    predictions = cross_val_predict(mnb, X, Y.ravel(), cv=4, n_jobs=1)\n",
    "    dfs[index][\"MNB\"][0] = metrics.accuracy_score(Y, predictions)\n",
    "    dfs[index][\"MNB\"][1] = metrics.precision_score(Y, predictions)\n",
    "    dfs[index][\"MNB\"][2] = metrics.recall_score(Y, predictions)\n",
    "    dfs[index][\"MNB\"][3] = metrics.f1_score(Y, predictions)\n",
    "    \n",
    "    mnb = LogisticRegression()\n",
    "    predictions = cross_val_predict(mnb, X, Y.ravel(), cv=4, n_jobs=1)\n",
    "    dfs[index][\"Bernoulli\"][0] = metrics.accuracy_score(Y, predictions)\n",
    "    dfs[index][\"Bernoulli\"][1] = metrics.precision_score(Y, predictions)\n",
    "    dfs[index][\"Bernoulli\"][2] = metrics.recall_score(Y, predictions)\n",
    "    dfs[index][\"Bernoulli\"][3] = metrics.f1_score(Y, predictions)\n",
    "    index += 1\n",
    "    \n",
    "print(\"Folds: \" + str(n_folds))\n",
    "print()\n",
    "for df in dfs:\n",
    "    print(df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973684210526\n",
      "0.966666666667\n",
      "1.0\n",
      "0.983050847458\n",
      "{0: 'o', 1: 'c', 2: 'e', 3: 'a', 4: 'n'}\n",
      "0.947368421053\n",
      "0.916666666667\n",
      "1.0\n",
      "0.95652173913\n",
      "{0: 'o', 1: 'c', 2: 'e', 3: 'a', 4: 'n'}\n",
      "0.947368421053\n",
      "0.904761904762\n",
      "1.0\n",
      "0.95\n",
      "{0: 'o', 1: 'c', 2: 'e', 3: 'a', 4: 'n'}\n",
      "0.947368421053\n",
      "0.935483870968\n",
      "1.0\n",
      "0.966666666667\n",
      "{0: 'o', 1: 'c', 2: 'e', 3: 'a', 4: 'n'}\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "{0: 'o', 1: 'c', 2: 'e', 3: 'a', 4: 'n'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "index = 0\n",
    "for Y in Y_array:\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X, Y.ravel())\n",
    "    coefs = mnb.coef_[0]\n",
    "\n",
    "    bag = list(bag_of_words)\n",
    "\n",
    "    word_coefs = []\n",
    "    for i in range(len(bag)):\n",
    "        word_coefs.append((bag[i], coefs[i]))\n",
    "\n",
    "    word_coefs.sort(key=lambda tup: tup[1])\n",
    "\n",
    "    predictions = mnb.predict(X)\n",
    "    print(metrics.accuracy_score(Y, predictions))\n",
    "    print(metrics.precision_score(Y, predictions))\n",
    "    print(metrics.recall_score(Y, predictions))\n",
    "    print(metrics.f1_score(Y, predictions))\n",
    "    \n",
    "    lookup = {\"ocean\".index(ch): ch for ch in \"ocean\"}\n",
    "    print(lookup)\n",
    "\n",
    "    # Use initial model counts for all but extroversion\n",
    "    joblib.dump(mnb, 'initial_model_counts_' + lookup[index] + '.pkl')\n",
    "    index += 1\n",
    "    joblib.dump(list(bag_of_words), 'initial_model_counts' + str(index) + '_bag_of_words.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds: 4\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.736842       0.5  0.736842\n",
      "Precision  0.756757  0.727273  0.787879\n",
      "Recall     0.965517  0.551724  0.896552\n",
      "F1         0.848485  0.627451   0.83871\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.421053  0.578947  0.578947\n",
      "Precision       0.5  0.636364       0.6\n",
      "Recall     0.545455  0.636364  0.818182\n",
      "F1         0.521739  0.636364  0.692308\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.552632  0.578947  0.526316\n",
      "Precision      0.55  0.578947   0.52381\n",
      "Recall     0.578947  0.578947  0.578947\n",
      "F1         0.564103  0.578947      0.55\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.763158  0.631579  0.710526\n",
      "Precision  0.763158  0.758621      0.75\n",
      "Recall            1  0.758621  0.931034\n",
      "F1         0.865672  0.758621  0.830769\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.710526  0.763158  0.789474\n",
      "Precision  0.681818    0.8125  0.789474\n",
      "Recall     0.789474  0.684211  0.789474\n",
      "F1         0.731707  0.742857  0.789474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X, Y.ravel())\n",
    "model = SelectFromModel(logit, prefit=True)\n",
    "\n",
    "X_new = model.transform(X)\n",
    "\n",
    "df_o = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_c = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_e = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_a = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_n = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "dfs = [df_o, df_c, df_e, df_a, df_n]\n",
    "\n",
    "index = 0\n",
    "for Y in Y_array:\n",
    "    mnb = GaussianNB()\n",
    "    predictions = cross_val_predict(mnb, X_new, Y.ravel(), cv=4, n_jobs=1)\n",
    "    dfs[index][\"Gaussian\"][0] = metrics.accuracy_score(Y, predictions)\n",
    "    dfs[index][\"Gaussian\"][1] = metrics.precision_score(Y, predictions)\n",
    "    dfs[index][\"Gaussian\"][2] = metrics.recall_score(Y, predictions)\n",
    "    dfs[index][\"Gaussian\"][3] = metrics.f1_score(Y, predictions)\n",
    "    \n",
    "    mnb = MultinomialNB()\n",
    "    predictions = cross_val_predict(mnb, X_new, Y.ravel(), cv=4, n_jobs=1)\n",
    "    dfs[index][\"MNB\"][0] = metrics.accuracy_score(Y, predictions)\n",
    "    dfs[index][\"MNB\"][1] = metrics.precision_score(Y, predictions)\n",
    "    dfs[index][\"MNB\"][2] = metrics.recall_score(Y, predictions)\n",
    "    dfs[index][\"MNB\"][3] = metrics.f1_score(Y, predictions)\n",
    "    \n",
    "    mnb = LogisticRegression()\n",
    "    predictions = cross_val_predict(mnb, X_new, Y.ravel(), cv=4, n_jobs=1)\n",
    "    dfs[index][\"Bernoulli\"][0] = metrics.accuracy_score(Y, predictions)\n",
    "    dfs[index][\"Bernoulli\"][1] = metrics.precision_score(Y, predictions)\n",
    "    dfs[index][\"Bernoulli\"][2] = metrics.recall_score(Y, predictions)\n",
    "    dfs[index][\"Bernoulli\"][3] = metrics.f1_score(Y, predictions)\n",
    "    index += 1\n",
    "    \n",
    "print(\"Folds: \" + str(n_folds))\n",
    "print()\n",
    "for df in dfs:\n",
    "    print(df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA to reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 1274)\n",
      "(38, 7)\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.736842  0.684211  0.815789\n",
      "Precision  0.806452  0.774194   0.84375\n",
      "Recall     0.862069  0.827586  0.931034\n",
      "F1         0.833333       0.8  0.885246\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.631579  0.526316  0.605263\n",
      "Precision  0.681818  0.583333   0.62963\n",
      "Recall     0.681818  0.636364  0.772727\n",
      "F1         0.681818  0.608696  0.693878\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.526316  0.473684  0.526316\n",
      "Precision  0.526316  0.466667  0.526316\n",
      "Recall     0.526316  0.368421  0.526316\n",
      "F1         0.526316  0.411765  0.526316\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.763158  0.815789  0.763158\n",
      "Precision    0.8125  0.823529  0.794118\n",
      "Recall     0.896552  0.965517  0.931034\n",
      "F1         0.852459  0.888889  0.857143\n",
      "\n",
      "           Gaussian       MNB Bernoulli\n",
      "Accuracy   0.710526  0.578947  0.684211\n",
      "Precision  0.681818  0.615385  0.684211\n",
      "Recall     0.789474  0.421053  0.684211\n",
      "F1         0.731707       0.5  0.684211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "orubt\n",
    "pca = PCA(n_components=7)\n",
    "pca.fit(X)\n",
    "X_new = pca.transform(X)\n",
    "\n",
    "df_o = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_c = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_e = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_a = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_n = pd.DataFrame(columns=[\"Gaussian\", \"MNB\", \"Bernoulli\"], index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "dfs = [df_o, df_c, df_e, df_a, df_n]\n",
    "\n",
    "index = 0\n",
    "for Y in Y_array:\n",
    "    mnb = LinearSVC()\n",
    "    predictions = cross_val_predict(mnb, X_new, Y.ravel(), cv=4, n_jobs=1)\n",
    "    dfs[index][\"Gaussian\"][0] = metrics.accuracy_score(Y, predictions)\n",
    "    dfs[index][\"Gaussian\"][1] = metrics.precision_score(Y, predictions)\n",
    "    dfs[index][\"Gaussian\"][2] = metrics.recall_score(Y, predictions)\n",
    "    dfs[index][\"Gaussian\"][3] = metrics.f1_score(Y, predictions)\n",
    "    \n",
    "    mnb = RandomForestClassifier()\n",
    "    predictions = cross_val_predict(mnb, X_new, Y.ravel(), cv=4, n_jobs=1)\n",
    "    dfs[index][\"MNB\"][0] = metrics.accuracy_score(Y, predictions)\n",
    "    dfs[index][\"MNB\"][1] = metrics.precision_score(Y, predictions)\n",
    "    dfs[index][\"MNB\"][2] = metrics.recall_score(Y, predictions)\n",
    "    dfs[index][\"MNB\"][3] = metrics.f1_score(Y, predictions)\n",
    "    \n",
    "    mnb = LogisticRegression()\n",
    "    predictions = cross_val_predict(mnb, X_new, Y.ravel(), cv=4, n_jobs=1)\n",
    "    dfs[index][\"Bernoulli\"][0] = metrics.accuracy_score(Y, predictions)\n",
    "    dfs[index][\"Bernoulli\"][1] = metrics.precision_score(Y, predictions)\n",
    "    dfs[index][\"Bernoulli\"][2] = metrics.recall_score(Y, predictions)\n",
    "    dfs[index][\"Bernoulli\"][3] = metrics.f1_score(Y, predictions)\n",
    "    index += 1\n",
    "\n",
    "for df in dfs:\n",
    "    print(df)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842105263158\n",
      "0.870967741935\n",
      "0.931034482759\n",
      "0.9\n",
      "\n",
      "0.684210526316\n",
      "0.678571428571\n",
      "0.863636363636\n",
      "0.76\n",
      "\n",
      "0.789473684211\n",
      "0.823529411765\n",
      "0.736842105263\n",
      "0.777777777778\n",
      "\n",
      "0.868421052632\n",
      "0.852941176471\n",
      "1.0\n",
      "0.920634920635\n",
      "\n",
      "0.815789473684\n",
      "0.8\n",
      "0.842105263158\n",
      "0.820512820513\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/pca_pca.pkl',\n",
       " 'model/pca_pca.pkl_01.npy',\n",
       " 'model/pca_pca.pkl_02.npy',\n",
       " 'model/pca_pca.pkl_03.npy',\n",
       " 'model/pca_pca.pkl_04.npy']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "index = 0\n",
    "lookup = {\"ocean\".index(ch): ch for ch in \"ocean\"}\n",
    "for Y in Y_array:\n",
    "    logit = LogisticRegression()\n",
    "    logit.fit(X_new, Y.ravel())\n",
    "    joblib.dump(logit, 'model/pca_' + lookup[index] + '.pkl')\n",
    "    index += 1\n",
    "    \n",
    "    predictions = logit.predict(X_new)\n",
    "    print(metrics.accuracy_score(Y, predictions))\n",
    "    print(metrics.precision_score(Y, predictions))\n",
    "    print(metrics.recall_score(Y, predictions))\n",
    "    print(metrics.f1_score(Y, predictions))\n",
    "    print()\n",
    "\n",
    "joblib.dump(list(bag_of_words), 'model/pca_bag_of_words.pkl')\n",
    "joblib.dump(pca, 'model/pca_pca.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
